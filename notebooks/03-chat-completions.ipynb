{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54880a74-1e5f-46db-a03f-141e1973d4a4",
   "metadata": {},
   "source": [
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536a604-b648-4262-a065-244dd50c44f6",
   "metadata": {},
   "source": [
    "Exploring chat completions with llama-jax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4dcea-5652-4fb1-afee-36f7dd5fde0d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4656138-830d-418c-a815-e75a381e9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from sys import stdout\n",
    "from time import time_ns, perf_counter_ns as timer\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "import llama_jax as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027865bd-fcee-4027-a4ca-74c9bbc2aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-02-22 17:54:39,140:jax._src.xla_bridge:1000: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "Available devices: [METAL(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1740264879.141274 75826958 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1740264879.152067 75826958 service.cc:145] XLA service 0x11b85cbd0 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740264879.152079 75826958 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1740264879.153610 75826958 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1740264879.153621 75826958 mps_client.cc:384] XLA backend will use up to 51539214336 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Available devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734568ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def tps_report(n_tokens: int):\n",
    "    start_time = timer()\n",
    "\n",
    "    yield\n",
    "    \n",
    "    stdout.write(\"\\n\\n\")\n",
    "    \n",
    "    duration = (timer() - start_time) / 1000000000\n",
    "    tps = n_tokens / duration\n",
    "    \n",
    "    print(f\"Generated {n_tokens} tokens in {duration:0.1f} s ({tps:0.1f} tps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5162a41-7a57-4cdb-ad98-a701a69164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(history: Sequence[Message], content: str) -> Sequence[Message]:\n",
    "#     messages = (*history, Message(role=\"user\", content=content))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3f298-b1cb-4c5c-b1ff-22c3b434e79b",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fbad4d-24cf-4a6f-8b20-baf9de01e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = time_ns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444377df-7a8f-4b79-9340-3313d1acce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure generator\n",
    "key = random.key(seed)\n",
    "config = ll.checkpoint.load_config(\"Llama3.2-3B-Instruct\")\n",
    "generator, key = ll.chat.generator(config, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bcfd7-3efc-4813-8e8f-728939e6c476",
   "metadata": {},
   "source": [
    "# Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9aa8c5-d6d7-464c-9ee4-5c6a4c55401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "993a7bfc-f2d8-4771-82dd-305fb2cd9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = next(generator([{\"role\": \"user\", \"content\": prompt}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c184d92-c370-4897-bd23-043eda65d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response.messages[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481c1ea-8e9b-4fbf-a327-de2a2024409c",
   "metadata": {},
   "source": [
    "# Prompt 0: Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a37c71-b5f9-4e9f-be02-648fb8985f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Count from 0 to 10.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89868a3-9c4e-4f0b-b9c4-576f04423409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we go:\n",
      "\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for event in generator([{\"role\": \"user\", \"content\": prompt}], stream=True):\n",
    "    stdout.write(\"\\n\\n\" if event.delta is None else event.delta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14976af0-cd8a-427f-96f0-301ef3ec55ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23075234-fadf-467b-b343-763d1fc6859a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
